# ðŸ“‹ TODO - Plan d'AmÃ©lioration Sharkoder

**Date de crÃ©ation** : 2025-11-07  
**Version analysÃ©e** : 1.0  
**Lignes de code totales** : ~12,000

---

## ðŸŽ¯ PRIORITÃ‰S

- ðŸ”´ **Critique** : Impact majeur sur maintenabilitÃ©, performance ou stabilitÃ©
- ðŸŸ¡ **Important** : AmÃ©liore significativement la qualitÃ© du code
- ðŸŸ¢ **SouhaitÃ©e** : Nice-to-have, optimisations futures

---

## ðŸ”´ PRIORITÃ‰ CRITIQUE

### 1. Refactoriser le Frontend Monolithique (index.html - 5299 lignes)

**Pourquoi** :

- Fichier unique Ã©norme impossible Ã  maintenir
- Transpilation Babel in-browser = performances dÃ©gradÃ©es
- Hot reload impossible
- Difficile de dÃ©boguer et tester
- Violation du principe de responsabilitÃ© unique (SRP)
- Bundle size Ã©norme (React chargÃ© via CDN)

**Comment** :

```
Ã‰tape 1 : Setup Build Process
â”œâ”€ Installer Webpack/Vite
â”œâ”€ Configurer Babel pour build-time transpilation
â”œâ”€ Setup React avec JSX natif
â””â”€ Configurer Hot Module Replacement (HMR)

Ã‰tape 2 : DÃ©coupage en Composants
renderer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Header.jsx
â”‚   â”‚   â”œâ”€â”€ WebDAVExplorer/
â”‚   â”‚   â”‚   â”œâ”€â”€ ConnectionPanel.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FileList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FileItem.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FolderStats.jsx
â”‚   â”‚   â”‚   â””â”€â”€ FileActions.jsx
â”‚   â”‚   â”œâ”€â”€ Queue/
â”‚   â”‚   â”‚   â”œâ”€â”€ QueueManager.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ QueueControls.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ QueueStats.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ JobList.jsx
â”‚   â”‚   â”‚   â””â”€â”€ JobItem.jsx
â”‚   â”‚   â”œâ”€â”€ Settings/
â”‚   â”‚   â”‚   â”œâ”€â”€ ConnectionSettings.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FFmpegSettings.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StorageSettings.jsx
â”‚   â”‚   â”‚   â””â”€â”€ AdvancedSettings.jsx
â”‚   â”‚   â”œâ”€â”€ Logs/
â”‚   â”‚   â”‚   â””â”€â”€ LogViewer.jsx
â”‚   â”‚   â””â”€â”€ common/
â”‚   â”‚       â”œâ”€â”€ Button.jsx
â”‚   â”‚       â”œâ”€â”€ ProgressBar.jsx
â”‚   â”‚       â”œâ”€â”€ LoadingScreen.jsx
â”‚   â”‚       â””â”€â”€ Modal.jsx
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useWebDAV.js
â”‚   â”‚   â”œâ”€â”€ useQueue.js
â”‚   â”‚   â”œâ”€â”€ useSettings.js
â”‚   â”‚   â””â”€â”€ useLogs.js
â”‚   â”œâ”€â”€ contexts/
â”‚   â”‚   â”œâ”€â”€ AppContext.jsx
â”‚   â”‚   â””â”€â”€ ThemeContext.jsx
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ formatters.js
â”‚   â”‚   â””â”€â”€ validators.js
â”‚   â”œâ”€â”€ App.jsx
â”‚   â””â”€â”€ index.jsx
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html (minimal)
â””â”€â”€ package.json (build scripts)
```

**Design Pattern** :

- **Component Composition** : Composants rÃ©utilisables et testables
- **Container/Presentational Pattern** : SÃ©parer logique mÃ©tier de l'affichage
- **Custom Hooks** : Encapsuler logique IPC et Ã©tat
- **Context API** : Ã‰tat global (queue, settings, logs)

**BÃ©nÃ©fices** :

- âœ… MaintenabilitÃ© +300%
- âœ… Performance (build optimisÃ©, code splitting)
- âœ… TestabilitÃ© (Jest + React Testing Library)
- âœ… Hot reload pour dÃ©veloppement
- âœ… Tree shaking et bundle optimization

**Estimation** : 3-5 jours de travail

---

### 2. Modulariser queue.js (1139 lignes)

**Pourquoi** :

- Fichier trop long avec responsabilitÃ©s multiples
- Difficile Ã  tester unitairement
- Logique de backup, download, encode, upload mÃ©langÃ©e
- Violation du Single Responsibility Principle (SRP)
- God Object anti-pattern

**Comment** :

```
Ã‰tape 1 : Extraire les Handlers de Pipeline
backend/queue/
â”œâ”€â”€ QueueManager.js (orchestration principale - 200 lignes)
â”œâ”€â”€ DownloadHandler.js (logique tÃ©lÃ©chargement - 150 lignes)
â”œâ”€â”€ EncodeHandler.js (logique encodage - 150 lignes)
â”œâ”€â”€ UploadHandler.js (logique upload - 150 lignes)
â”œâ”€â”€ BackupManager.js (gestion backups - 200 lignes)
â”œâ”€â”€ JobStateMachine.js (machine Ã  Ã©tats - 150 lignes)
â””â”€â”€ index.js (exports)

Ã‰tape 2 : CrÃ©er une State Machine Explicite
class JobStateMachine {
  states = {
    waiting: { next: ['downloading', 'failed'] },
    downloading: { next: ['ready_encode', 'failed', 'paused'] },
    ready_encode: { next: ['encoding'] },
    encoding: { next: ['awaiting_approval', 'ready_upload', 'failed'] },
    awaiting_approval: { next: ['ready_upload', 'failed'] },
    ready_upload: { next: ['uploading'] },
    uploading: { next: ['completed', 'failed'] },
    paused: { next: ['waiting'] },
    failed: { next: ['waiting'] },
    completed: { next: [] }
  }

  transition(fromState, toState, job) {
    // Validation + events + hooks
  }
}

Ã‰tape 3 : Extraire BackupManager
class BackupManager {
  constructor(config) { ... }

  async createLocalOriginalBackup(filePath) { ... }
  async createLocalEncodedBackup(filePath) { ... }
  async createServerBackup(remotePath) { ... }
  async restoreFromBackup(backupType, jobId) { ... }
  async cleanupBackups(job, config) { ... }
}
```

**Design Pattern** :

- **State Pattern** : Machine Ã  Ã©tats explicite pour les transitions de jobs
- **Strategy Pattern** : DiffÃ©rentes stratÃ©gies de backup
- **Handler Pattern** : Chaque phase du pipeline = handler dÃ©diÃ©
- **Facade Pattern** : QueueManager comme faÃ§ade orchestrant les handlers

**Architecture ProposÃ©e** :

```
QueueManager (Facade)
â”œâ”€> DownloadHandler (Ã©tape 1)
â”œâ”€> EncodeHandler (Ã©tape 2)
â”œâ”€> UploadHandler (Ã©tape 3)
â”œâ”€> BackupManager (transversal)
â””â”€> JobStateMachine (Ã©tat)
```

**BÃ©nÃ©fices** :

- âœ… TestabilitÃ© (chaque handler isolÃ©)
- âœ… LisibilitÃ© (fichiers < 200 lignes)
- âœ… RÃ©utilisabilitÃ© (BackupManager utilisable ailleurs)
- âœ… Maintenance facilitÃ©e
- âœ… Extension facile (nouveau handler = nouveau fichier)

**Estimation** : 2-3 jours de travail

---

### 3. Refactoriser main.js - IPC Handlers (1587 lignes)

**Pourquoi** :

- ~60 IPC handlers dans un seul fichier
- Difficile de trouver un handler spÃ©cifique
- Couplage fort entre tous les handlers
- Violation du principe Open/Closed
- Fichier qui grossit Ã  chaque nouvelle feature

**Comment** :

```
Ã‰tape 1 : CrÃ©er un IPC Router Pattern
backend/ipc/
â”œâ”€â”€ router.js (IPC router principal)
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ webdav.handlers.js
â”‚   â”œâ”€â”€ queue.handlers.js
â”‚   â”œâ”€â”€ settings.handlers.js
â”‚   â”œâ”€â”€ config.handlers.js
â”‚   â”œâ”€â”€ preset.handlers.js
â”‚   â””â”€â”€ transfer.handlers.js
â””â”€â”€ middleware/
    â”œâ”€â”€ errorHandler.js
    â”œâ”€â”€ logger.js
    â””â”€â”€ validator.js

Ã‰tape 2 : ImplÃ©menter le Router
// backend/ipc/router.js
class IPCRouter {
  constructor(ipcMain) {
    this.ipcMain = ipcMain;
    this.handlers = new Map();
    this.middleware = [];
  }

  use(middleware) {
    this.middleware.push(middleware);
  }

  handle(channel, handler) {
    this.handlers.set(channel, handler);
    this.ipcMain.handle(channel, async (event, ...args) => {
      try {
        // Execute middleware chain
        for (const mw of this.middleware) {
          await mw(event, args);
        }
        // Execute handler
        return await handler(event, ...args);
      } catch (error) {
        logger.error(`IPC Error [${channel}]:`, error);
        return { success: false, error: error.message };
      }
    });
  }

  registerHandlers(handlers) {
    Object.entries(handlers).forEach(([channel, handler]) => {
      this.handle(channel, handler);
    });
  }
}

// backend/ipc/handlers/webdav.handlers.js
const webdavHandlers = (transferManager, configManager) => ({
  'webdav:connect': async (event) => {
    await transferManager.ensureConnection();
    return { success: true };
  },

  'webdav:listDirectory': async (event, remotePath) => {
    const items = await transferManager.listDirectory(remotePath || '/');
    const extractDuration = configManager.get('advanced.behavior.extract_video_duration');

    if (extractDuration && transferManager.webdavManager) {
      // Enrichment logic...
    }
    return { success: true, items };
  },

  // ... autres handlers WebDAV
});

// main.js (simplifiÃ© Ã  ~300 lignes)
const router = new IPCRouter(ipcMain);

// Middleware global
router.use(loggingMiddleware);
router.use(errorHandlingMiddleware);

// Enregistrer les handlers par domaine
router.registerHandlers(webdavHandlers(transferManager, configManager));
router.registerHandlers(queueHandlers(queueManager));
router.registerHandlers(settingsHandlers(configManager));
```

**Design Pattern** :

- **Router Pattern** : Dispatch des handlers IPC par domaine
- **Middleware Pattern** : Chain of Responsibility pour logging/errors
- **Factory Pattern** : Handlers crÃ©Ã©s via factories avec dÃ©pendances
- **Dependency Injection** : Managers injectÃ©s dans les handlers

**Architecture** :

```
IPCRouter (Orchestrator)
â”œâ”€> Middleware Chain
â”‚   â”œâ”€> Logger
â”‚   â”œâ”€> Validator
â”‚   â””â”€> Error Handler
â””â”€> Handler Domains
    â”œâ”€> WebDAV Handlers
    â”œâ”€> Queue Handlers
    â”œâ”€> Settings Handlers
    â””â”€> Config Handlers
```

**BÃ©nÃ©fices** :

- âœ… SÃ©paration des responsabilitÃ©s
- âœ… main.js rÃ©duit Ã  ~300 lignes (orchestration pure)
- âœ… Handlers testables isolÃ©ment
- âœ… Middleware rÃ©utilisables
- âœ… Extension facile (nouveau domaine = nouveau fichier)
- âœ… Gestion d'erreur centralisÃ©e

**Estimation** : 2 jours de travail

---

### 4. Ã‰liminer le Code DupliquÃ©

**Pourquoi** :

- Violation du principe DRY (Don't Repeat Yourself)
- Bugs corrigÃ©s Ã  un endroit mais pas dans les duplicatas
- Maintenance multipliÃ©e
- Tests multipliÃ©s

**Duplications dÃ©tectÃ©es** :

#### 4.1 `getBackupPath()` (webdav.js + sftp.js)

**Comment** :

```javascript
// backend/utils.js (ajouter)
/**
 * Generate backup filename: <filename>.bak.<ext>
 * Example: video.mkv -> video.bak.mkv
 * @param {string} originalPath - Original file path (posix format)
 * @returns {string} Backup path
 */
function getBackupPath(originalPath) {
  const parsedPath = path.posix.parse(originalPath);
  return path.posix.join(parsedPath.dir, `${parsedPath.name}.bak${parsedPath.ext}`);
}

// webdav.js et sftp.js
const { logger, formatBytes, isVideoFile, getBackupPath } = require("./utils");
// Supprimer la fonction locale
```

#### 4.2 Progress Tracking Logic (webdav.js + sftp.js)

**Comment** :

```javascript
// backend/ProgressTracker.js (nouveau)
class ProgressTracker {
  constructor() {
    this.startTime = null;
    this.lastUpdate = null;
    this.totalSize = 0;
    this.downloadedSize = 0;
  }

  start(totalSize) {
    this.startTime = Date.now();
    this.totalSize = totalSize;
  }

  update(downloadedSize) {
    this.downloadedSize = downloadedSize;
    this.lastUpdate = Date.now();

    const elapsed = (this.lastUpdate - this.startTime) / 1000;
    const speed = downloadedSize / elapsed;
    const percentage = (downloadedSize / this.totalSize) * 100;
    const eta = speed > 0 ? (this.totalSize - downloadedSize) / speed : 0;

    return {
      percentage: Math.min(percentage, 100),
      downloaded: formatBytes(downloadedSize),
      total: formatBytes(this.totalSize),
      speed: formatBytes(speed) + "/s",
      eta: Math.round(eta),
      etaFormatted: formatDuration(eta),
    };
  }

  reset() {
    this.startTime = null;
    this.downloadedSize = 0;
    this.totalSize = 0;
  }
}

// Utilisation dans webdav.js et sftp.js
const tracker = new ProgressTracker();
tracker.start(totalSize);
// Dans le stream
const progress = tracker.update(downloadedSize);
if (onProgress) onProgress(progress);
```

**Design Pattern** :

- **Strategy Pattern** : ProgressTracker abstrait la logique de calcul
- **Single Responsibility** : Une classe, une responsabilitÃ©

**BÃ©nÃ©fices** :

- âœ… Code partagÃ© et testÃ© une seule fois
- âœ… Bugs corrigÃ©s globalement
- âœ… Ajout de features (pause/resume) centralisÃ©

**Estimation** : 0.5 jour de travail

---

## ðŸŸ¡ PRIORITÃ‰ IMPORTANTE

### 5. SystÃ¨me de Migrations DB VersionnÃ©

**Pourquoi** :

- 18 try/catch rÃ©pÃ©titifs dans db.js
- Impossible de savoir quelle version du schÃ©ma est installÃ©e
- Pas de rollback possible
- Risque d'incohÃ©rence sur des installations anciennes
- Code fragile et difficile Ã  maintenir

**Comment** :

```
Ã‰tape 1 : CrÃ©er un Migration System
backend/db/
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ 001_initial_schema.js
â”‚   â”œâ”€â”€ 002_add_metadata_columns.js
â”‚   â”œâ”€â”€ 003_add_backup_paths.js
â”‚   â”œâ”€â”€ 004_add_encoding_params.js
â”‚   â””â”€â”€ index.js
â”œâ”€â”€ migrator.js
â””â”€â”€ index.js

Ã‰tape 2 : ImplÃ©menter le Migrator
// backend/db/migrator.js
class DatabaseMigrator {
  constructor(db) {
    this.db = db;
    this.migrations = [];
  }

  register(migration) {
    this.migrations.push(migration);
    this.migrations.sort((a, b) => a.version - b.version);
  }

  async getCurrentVersion() {
    try {
      const result = this.db.exec('SELECT version FROM schema_version LIMIT 1');
      return result[0]?.values[0]?.[0] || 0;
    } catch {
      // Table doesn't exist, version 0
      return 0;
    }
  }

  async setVersion(version) {
    // Create table if not exists
    this.db.run(`
      CREATE TABLE IF NOT EXISTS schema_version (
        version INTEGER PRIMARY KEY,
        applied_at TEXT DEFAULT CURRENT_TIMESTAMP
      )
    `);
    this.db.run('DELETE FROM schema_version');
    this.db.run('INSERT INTO schema_version (version) VALUES (?)', [version]);
  }

  async migrate() {
    const currentVersion = await this.getCurrentVersion();
    logger.info(`Current DB version: ${currentVersion}`);

    const pendingMigrations = this.migrations.filter(
      m => m.version > currentVersion
    );

    if (pendingMigrations.length === 0) {
      logger.info('Database is up to date');
      return;
    }

    logger.info(`Applying ${pendingMigrations.length} migrations...`);

    for (const migration of pendingMigrations) {
      try {
        logger.info(`Applying migration ${migration.version}: ${migration.name}`);
        await migration.up(this.db);
        await this.setVersion(migration.version);
        logger.info(`âœ“ Migration ${migration.version} applied`);
      } catch (error) {
        logger.error(`âœ— Migration ${migration.version} failed:`, error);
        throw error;
      }
    }

    logger.info('All migrations applied successfully');
  }

  async rollback(targetVersion) {
    const currentVersion = await this.getCurrentVersion();
    const migrationsToRollback = this.migrations
      .filter(m => m.version > targetVersion && m.version <= currentVersion)
      .reverse();

    for (const migration of migrationsToRollback) {
      if (!migration.down) {
        throw new Error(`Migration ${migration.version} has no rollback`);
      }
      await migration.down(this.db);
      await this.setVersion(migration.version - 1);
    }
  }
}

// backend/db/migrations/001_initial_schema.js
module.exports = {
  version: 1,
  name: 'Create jobs table',
  up: async (db) => {
    db.run(`
      CREATE TABLE IF NOT EXISTS jobs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        filepath TEXT NOT NULL UNIQUE,
        size INTEGER NOT NULL,
        codec_before TEXT,
        codec_after TEXT,
        status TEXT NOT NULL DEFAULT 'waiting',
        progress REAL DEFAULT 0,
        eta INTEGER,
        started_at TEXT,
        finished_at TEXT,
        error TEXT,
        retry_count INTEGER DEFAULT 0,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
      )
    `);
  },
  down: async (db) => {
    db.run('DROP TABLE IF EXISTS jobs');
  }
};

// backend/db/migrations/002_add_metadata_columns.js
module.exports = {
  version: 2,
  name: 'Add metadata columns',
  up: async (db) => {
    db.run('ALTER TABLE jobs ADD COLUMN container TEXT');
    db.run('ALTER TABLE jobs ADD COLUMN resolution TEXT');
    db.run('ALTER TABLE jobs ADD COLUMN duration REAL');
    db.run('ALTER TABLE jobs ADD COLUMN bitrate INTEGER');
    db.run('ALTER TABLE jobs ADD COLUMN audio INTEGER DEFAULT 0');
    db.run('ALTER TABLE jobs ADD COLUMN audioCodec TEXT');
    db.run('ALTER TABLE jobs ADD COLUMN subtitles INTEGER DEFAULT 0');
  },
  down: async (db) => {
    // SQLite doesn't support DROP COLUMN easily
    // Would require recreating table
    throw new Error('Rollback not supported for this migration');
  }
};

// backend/db/index.js (initDatabase modifiÃ©)
const migrator = new DatabaseMigrator(db);

// Register all migrations
const migrations = require('./migrations');
migrations.forEach(m => migrator.register(m));

// Run migrations
await migrator.migrate();
```

**Design Pattern** :

- **Command Pattern** : Chaque migration = command up/down
- **Chain of Responsibility** : Migrations appliquÃ©es en sÃ©quence
- **Template Method** : Structure commune pour toutes les migrations

**BÃ©nÃ©fices** :

- âœ… Suppression des 18 try/catch
- âœ… TraÃ§abilitÃ© des versions de schÃ©ma
- âœ… PossibilitÃ© de rollback
- âœ… Migrations testables
- âœ… Documentation implicite des changements de schÃ©ma

**Estimation** : 1 jour de travail

---

### 6. ImplÃ©menter checkDiskSpace() RÃ©el

**Pourquoi** :

- Actuellement un placeholder (retourne toujours 50GB)
- Risque de remplir le disque
- Ã‰checs d'encodage silencieux
- Pas de validation avant tÃ©lÃ©chargement

**Comment** :

```javascript
// Installer la dÃ©pendance
npm install check-disk-space

// backend/utils.js
const checkDiskSpace = require('check-disk-space').default;

/**
 * Check available disk space on a drive
 * @param {string} dirPath - Directory path to check
 * @returns {Promise<{free: number, size: number}>} Disk space info in bytes
 */
const checkDiskSpaceReal = async (dirPath) => {
  try {
    // check-disk-space expects a drive path on Windows (C:\)
    // or mount point on Unix (/)
    const drive = process.platform === 'win32'
      ? path.parse(dirPath).root
      : '/';

    const diskSpace = await checkDiskSpace(drive);

    logger.debug(`Disk space for ${drive}: ${formatBytes(diskSpace.free)} free of ${formatBytes(diskSpace.size)}`);

    return {
      free: diskSpace.free,
      size: diskSpace.size,
      used: diskSpace.size - diskSpace.free,
      percentUsed: ((diskSpace.size - diskSpace.free) / diskSpace.size) * 100
    };
  } catch (error) {
    logger.error('Failed to check disk space:', error);
    // Fallback to old behavior
    return {
      free: 50 * 1024 * 1024 * 1024,
      size: 100 * 1024 * 1024 * 1024
    };
  }
};

/**
 * Ensure enough disk space is available before operation
 * @param {string} dirPath - Directory path
 * @param {number} requiredBytes - Required space in bytes
 * @param {number} bufferPercent - Safety buffer (default 10%)
 * @returns {Promise<boolean>}
 * @throws {Error} If insufficient space
 */
const ensureSpaceAvailable = async (dirPath, requiredBytes, bufferPercent = 10) => {
  const space = await checkDiskSpaceReal(dirPath);
  const requiredWithBuffer = requiredBytes * (1 + bufferPercent / 100);

  if (space.free < requiredWithBuffer) {
    const message = `Insufficient disk space. Required: ${formatBytes(requiredWithBuffer)} (including ${bufferPercent}% buffer), Available: ${formatBytes(space.free)}`;
    logger.error(message);
    throw new Error(message);
  }

  logger.info(`Disk space check passed: ${formatBytes(space.free)} available, ${formatBytes(requiredWithBuffer)} required`);
  return true;
};

// Utilisation dans queue.js avant download
async downloadPhase(job) {
  // Check disk space before downloading
  await ensureSpaceAvailable(
    this.config.storage.local_temp,
    job.size,
    20 // 20% buffer for temporary files during encoding
  );

  // Proceed with download...
}
```

**BÃ©nÃ©fices** :

- âœ… Protection contre remplissage disque
- âœ… Alertes prÃ©coces
- âœ… Ã‰vite Ã©checs en milieu d'encodage
- âœ… Messages d'erreur informatifs

**Estimation** : 0.5 jour de travail

---

### 7. Ajouter Tests AutomatisÃ©s

**Pourquoi** :

- Aucun test dÃ©tectÃ© dans le projet
- Risque de rÃ©gression Ã  chaque modification
- Difficile de refactoriser en confiance
- Pas de validation automatique des PRs

**Comment** :

```
Ã‰tape 1 : Setup Testing Infrastructure
npm install --save-dev jest @testing-library/react @testing-library/jest-dom
npm install --save-dev electron-mock-ipc

Ã‰tape 2 : Structure de Tests
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ utils.test.js
â”‚   â”‚   â”œâ”€â”€ db.test.js
â”‚   â”‚   â”œâ”€â”€ encode.test.js
â”‚   â”‚   â”œâ”€â”€ BackupManager.test.js
â”‚   â”‚   â””â”€â”€ ProgressTracker.test.js
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ FileItem.test.jsx
â”‚       â”‚   â”œâ”€â”€ JobItem.test.jsx
â”‚       â”‚   â””â”€â”€ ProgressBar.test.jsx
â”‚       â””â”€â”€ hooks/
â”‚           â”œâ”€â”€ useWebDAV.test.js
â”‚           â””â”€â”€ useQueue.test.js
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ queue-pipeline.test.js
â”‚   â”œâ”€â”€ webdav-operations.test.js
â”‚   â””â”€â”€ ipc-handlers.test.js
â””â”€â”€ e2e/
    â””â”€â”€ encoding-workflow.test.js

Ã‰tape 3 : Exemples de Tests
// tests/unit/backend/utils.test.js
const { formatBytes, calculateETA, isVideoFile } = require('../../../backend/utils');

describe('formatBytes', () => {
  test('formats bytes correctly', () => {
    expect(formatBytes(0)).toBe('0 Octets');
    expect(formatBytes(1024)).toBe('1 Ko');
    expect(formatBytes(1048576)).toBe('1 Mo');
    expect(formatBytes(1073741824)).toBe('1 Go');
  });
});

describe('isVideoFile', () => {
  test('identifies video files', () => {
    expect(isVideoFile('movie.mkv')).toBe(true);
    expect(isVideoFile('video.mp4')).toBe(true);
    expect(isVideoFile('doc.pdf')).toBe(false);
  });
});

// tests/unit/backend/BackupManager.test.js
const BackupManager = require('../../../backend/queue/BackupManager');

describe('BackupManager', () => {
  let backupManager;

  beforeEach(() => {
    backupManager = new BackupManager({
      storage: {
        local_backup: '/tmp/test-backup'
      }
    });
  });

  test('creates local backup path correctly', () => {
    const path = backupManager.createLocalBackupPath('/remote/video.mkv');
    expect(path).toMatch(/\/tmp\/test-backup\/\d{4}-\d{2}-\d{2}\/video\.mkv/);
  });

  test('creates server backup path correctly', () => {
    const path = backupManager.createServerBackupPath('/remote/video.mkv');
    expect(path).toBe('/remote/video.bak.mkv');
  });
});

// tests/integration/queue-pipeline.test.js
describe('Queue Pipeline Integration', () => {
  test('complete job workflow', async () => {
    const job = await queueManager.addJob('/remote/test.mkv', {
      size: 1024 * 1024 * 100, // 100MB
      codec_before: 'h264'
    });

    await queueManager.start();

    // Wait for completion
    await new Promise(resolve => {
      queueManager.on('jobComplete', (completedJob) => {
        if (completedJob.id === job.id) resolve();
      });
    });

    const finalJob = await getJob(job.id);
    expect(finalJob.status).toBe('completed');
    expect(finalJob.codec_after).toBe('hevc');
  });
});

Ã‰tape 4 : Configuration Jest
// package.json
{
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "test:coverage": "jest --coverage"
  },
  "jest": {
    "testEnvironment": "node",
    "coverageDirectory": "coverage",
    "collectCoverageFrom": [
      "backend/**/*.js",
      "!backend/**/*.test.js"
    ],
    "testMatch": [
      "**/tests/**/*.test.js"
    ]
  }
}
```

**Design Pattern** :

- **AAA Pattern** : Arrange, Act, Assert
- **Factory Pattern** : Factories pour crÃ©er donnÃ©es de test
- **Mock Pattern** : Mocks pour IPC, filesystem, network

**BÃ©nÃ©fices** :

- âœ… DÃ©tection prÃ©coce des bugs
- âœ… Refactoring sans peur
- âœ… Documentation vivante du code
- âœ… CI/CD possible
- âœ… Couverture de code mesurable

**Objectif de couverture** : >80% pour utils, db, encode

**Estimation** : 3-4 jours de travail

---

### 8. CrÃ©er une Classe Abstraite BaseTransferManager

**Pourquoi** :

- webdav.js et sftp.js partagent beaucoup de logique
- Code dupliquÃ© (upload, download, progress tracking)
- Difficile d'ajouter un nouveau protocole (FTP, S3)
- Violation du DRY principle

**Comment** :

```javascript
// backend/transfer/BaseTransferManager.js
const { EventEmitter } = require("events");
const ProgressTracker = require("./ProgressTracker");

/**
 * Abstract base class for transfer managers
 * Implements common logic for upload/download with progress tracking
 */
class BaseTransferManager extends EventEmitter {
  constructor(config) {
    super();
    this.config = config;
    this.connected = false;
    this.progressTracker = new ProgressTracker();
  }

  // Abstract methods (must be implemented by subclasses)
  async connect() {
    throw new Error("connect() must be implemented");
  }

  async disconnect() {
    throw new Error("disconnect() must be implemented");
  }

  async _uploadStream(localPath, remotePath) {
    throw new Error("_uploadStream() must be implemented");
  }

  async _downloadStream(remotePath, localPath) {
    throw new Error("_downloadStream() must be implemented");
  }

  // Common implementation (shared by all subclasses)
  async ensureConnection() {
    if (!this.connected) {
      await this.connect();
    }
  }

  async uploadFile(localPath, remotePath, onProgress = null) {
    await this.ensureConnection();

    const stats = await fs.stat(localPath);
    const totalSize = stats.size;

    this.progressTracker.start(totalSize);

    // Backup logic (if configured)
    if (this.config.advanced?.behavior?.create_backups) {
      await this.createBackup(remotePath);
    }

    // Delegate to subclass implementation
    await this._uploadStream(localPath, remotePath, (uploadedSize) => {
      const progress = this.progressTracker.update(uploadedSize);
      if (onProgress) onProgress(progress);
      this.emit("uploadProgress", { remotePath, ...progress });
    });

    this.progressTracker.reset();
    return { success: true };
  }

  async downloadFile(remotePath, localPath, onProgress = null) {
    await this.ensureConnection();

    const stat = await this.stat(remotePath);
    const totalSize = stat.size;

    this.progressTracker.start(totalSize);

    // Resume logic
    let resumeFrom = 0;
    if (await fs.pathExists(localPath)) {
      const localStats = await fs.stat(localPath);
      if (localStats.size < totalSize) {
        resumeFrom = localStats.size;
      }
    }

    // Delegate to subclass implementation
    await this._downloadStream(remotePath, localPath, resumeFrom, (downloadedSize) => {
      const progress = this.progressTracker.update(downloadedSize);
      if (onProgress) onProgress(progress);
      this.emit("downloadProgress", { remotePath, ...progress });
    });

    this.progressTracker.reset();
    return { success: true };
  }

  async createBackup(remotePath) {
    const backupPath = getBackupPath(remotePath);

    // Check if original exists
    if (await this.exists(remotePath)) {
      logger.info(`Creating backup: ${backupPath}`);
      await this.rename(remotePath, backupPath);
    }
  }
}

// backend/transfer/WebDAVManager.js (refactorÃ©)
const BaseTransferManager = require("./BaseTransferManager");

class WebDAVManager extends BaseTransferManager {
  constructor(config) {
    super(config);
    this.client = null;
  }

  async connect() {
    // Implementation spÃ©cifique WebDAV...
    this.connected = true;
  }

  async _uploadStream(localPath, remotePath, onProgress) {
    // Implementation spÃ©cifique WebDAV...
  }

  async _downloadStream(remotePath, localPath, resumeFrom, onProgress) {
    // Implementation spÃ©cifique WebDAV...
  }

  async stat(remotePath) {
    // Implementation spÃ©cifique WebDAV...
  }

  async exists(remotePath) {
    // Implementation spÃ©cifique WebDAV...
  }

  async rename(oldPath, newPath) {
    // Implementation spÃ©cifique WebDAV...
  }
}

// backend/transfer/SftpManager.js (refactorÃ©)
class SftpManager extends BaseTransferManager {
  // MÃªme pattern...
}

// Facile d'ajouter un nouveau protocole
class FtpManager extends BaseTransferManager {
  // Juste implÃ©menter les mÃ©thodes abstraites
}

class S3Manager extends BaseTransferManager {
  // Juste implÃ©menter les mÃ©thodes abstraites
}
```

**Design Pattern** :

- **Template Method Pattern** : Classe de base dÃ©finit le flow, sous-classes implÃ©mentent les dÃ©tails
- **Strategy Pattern** : DiffÃ©rentes stratÃ©gies de transfert (WebDAV, SFTP, FTP)
- **DRY Principle** : Code commun factorisÃ©

**BÃ©nÃ©fices** :

- âœ… Suppression de ~400 lignes de code dupliquÃ©
- âœ… Extension facile (nouveau protocole = implÃ©menter 4-5 mÃ©thodes)
- âœ… Logique de backup centralisÃ©e
- âœ… Progress tracking unifiÃ©
- âœ… Tests sur la classe de base bÃ©nÃ©ficient Ã  tous les protocoles

**Estimation** : 2 jours de travail

---

## ðŸŸ¢ PRIORITÃ‰ SOUHAITÃ‰E

### 9. Ajouter Rotation des Logs

**Pourquoi** :

- Fichier sharkoder.log grandit indÃ©finiment
- Risque de remplir le disque sur installations long-terme
- Difficile de trouver logs rÃ©cents dans un fichier de plusieurs Go
- Pas de nettoyage automatique

**Comment** :

```javascript
// Installer winston avec rotation
npm install winston winston-daily-rotate-file

// backend/utils.js (refactoriser Logger)
const winston = require('winston');
const DailyRotateFile = require('winston-daily-rotate-file');
const path = require('path');

class Logger {
  constructor() {
    const logDir = path.join(__dirname, '..', 'logs');

    // Console transport
    const consoleTransport = new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
        winston.format.printf(({ timestamp, level, message, ...meta }) => {
          const metaStr = Object.keys(meta).length ? JSON.stringify(meta) : '';
          return `[${timestamp}] [${level}] ${message} ${metaStr}`;
        })
      )
    });

    // Daily rotate file transport
    const fileTransport = new DailyRotateFile({
      filename: path.join(logDir, 'sharkoder-%DATE%.log'),
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',        // Rotate when file reaches 20MB
      maxFiles: '14d',       // Keep logs for 14 days
      zippedArchive: true,   // Compress old logs
      format: winston.format.combine(
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
        winston.format.json()
      )
    });

    // Error-only file transport
    const errorFileTransport = new DailyRotateFile({
      filename: path.join(logDir, 'error-%DATE%.log'),
      datePattern: 'YYYY-MM-DD',
      level: 'error',
      maxSize: '10m',
      maxFiles: '30d',
      zippedArchive: true,
      format: winston.format.combine(
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
        winston.format.json()
      )
    });

    this.logger = winston.createLogger({
      level: 'info',
      transports: [
        consoleTransport,
        fileTransport,
        errorFileTransport
      ],
      exitOnError: false
    });

    // Log rotation events
    fileTransport.on('rotate', (oldFilename, newFilename) => {
      this.logger.info(`Log rotated: ${oldFilename} -> ${newFilename}`);
    });
  }

  info(message, ...meta) {
    this.logger.info(message, ...meta);
  }

  warn(message, ...meta) {
    this.logger.warn(message, ...meta);
  }

  error(message, ...meta) {
    this.logger.error(message, ...meta);
  }

  debug(message, ...meta) {
    this.logger.debug(message, ...meta);
  }
}
```

**Configuration possible** :

```json
// sharkoder.config.json
{
  "advanced": {
    "logging": {
      "level": "info",
      "max_file_size": "20m",
      "max_files": "14d",
      "compress": true,
      "separate_errors": true
    }
  }
}
```

**BÃ©nÃ©fices** :

- âœ… Logs organisÃ©s par date
- âœ… Nettoyage automatique (14 jours)
- âœ… Compression des anciens logs
- âœ… Fichier errors sÃ©parÃ© pour troubleshooting
- âœ… Protection contre remplissage disque

**Estimation** : 0.5 jour de travail

---

### 10. Ajouter Support d'Autres GPU (AMD, Intel)

**Pourquoi** :

- Actuellement uniquement NVIDIA NVENC supportÃ©
- Exclut les utilisateurs AMD (VCE/AMF) et Intel (Quick Sync)
- Limitation artificielle de l'audience

**Comment** :

```javascript
// backend/encode.js (refactoriser)
class VideoEncoder extends EventEmitter {
  constructor(config, transferManager) {
    super();
    this.config = config;
    this.transferManager = transferManager;
    this.gpuCapabilities = null;
  }

  /**
   * Detect all available GPU encoders
   * @returns {Promise<Object>} GPU capabilities
   */
  async detectGPUCapabilities() {
    const capabilities = {
      nvidia: false,
      amd: false,
      intel: false,
      preferred: null,
      encoders: [],
    };

    // Test NVIDIA NVENC
    try {
      await this.testEncoder("hevc_nvenc");
      capabilities.nvidia = true;
      capabilities.encoders.push({
        name: "NVIDIA NVENC",
        codec: "hevc_nvenc",
        vendor: "nvidia",
        priority: 1,
      });
    } catch (e) {
      logger.debug("NVENC not available");
    }

    // Test AMD VCE/AMF
    try {
      await this.testEncoder("hevc_amf");
      capabilities.amd = true;
      capabilities.encoders.push({
        name: "AMD AMF",
        codec: "hevc_amf",
        vendor: "amd",
        priority: 2,
      });
    } catch (e) {
      logger.debug("AMD AMF not available");
    }

    // Test Intel Quick Sync
    try {
      await this.testEncoder("hevc_qsv");
      capabilities.intel = true;
      capabilities.encoders.push({
        name: "Intel Quick Sync",
        codec: "hevc_qsv",
        vendor: "intel",
        priority: 3,
      });
    } catch (e) {
      logger.debug("Intel QSV not available");
    }

    // Sort by priority and select preferred
    capabilities.encoders.sort((a, b) => a.priority - b.priority);
    capabilities.preferred = capabilities.encoders[0] || null;

    this.gpuCapabilities = capabilities;

    logger.info("GPU Detection Results:", {
      nvidia: capabilities.nvidia,
      amd: capabilities.amd,
      intel: capabilities.intel,
      preferred: capabilities.preferred?.name || "CPU (x265)",
    });

    return capabilities;
  }

  /**
   * Build encoder-specific arguments
   */
  buildGPUArgs(encoder, config) {
    switch (encoder.vendor) {
      case "nvidia":
        return this.buildNVENCArgs(config);
      case "amd":
        return this.buildAMFArgs(config);
      case "intel":
        return this.buildQSVArgs(config);
      default:
        return [];
    }
  }

  buildNVENCArgs(config) {
    // Existing NVENC logic...
    return [
      "-c:v",
      "hevc_nvenc",
      "-preset",
      config.encode_preset || "p7",
      "-cq",
      config.cq || 18,
      // ... autres params
    ];
  }

  buildAMFArgs(config) {
    return [
      "-c:v",
      "hevc_amf",
      "-quality",
      "quality", // quality, balanced, speed
      "-rc",
      "vbr_latency", // cbr, vbr_peak, vbr_latency
      "-qp_i",
      config.cq || 18,
      "-qp_p",
      config.cq || 18,
      "-usage",
      "ultralowlatency",
      "-profile:v",
      "main10",
    ];
  }

  buildQSVArgs(config) {
    return [
      "-c:v",
      "hevc_qsv",
      "-preset",
      "veryslow", // veryfast, faster, fast, medium, slow, slower, veryslow
      "-global_quality",
      config.cq || 18,
      "-look_ahead",
      1,
      "-profile:v",
      "main10",
    ];
  }

  async encodeVideo(inputPath, outputPath, onProgress) {
    // Auto-detect GPU on first encode
    if (!this.gpuCapabilities) {
      await this.detectGPUCapabilities();
    }

    // Select encoder
    const encoder = this.config.ffmpeg.force_gpu && this.gpuCapabilities.preferred ? this.gpuCapabilities.preferred : { vendor: "cpu", codec: "libx265" };

    logger.info(`Encoding with: ${encoder.name || "CPU x265"}`);

    // Build arguments
    const videoArgs = encoder.vendor === "cpu" ? this.buildCPUArgs(this.config.ffmpeg) : this.buildGPUArgs(encoder, this.config.ffmpeg);

    // ... reste de l'encodage
  }
}
```

**Configuration UI** :

```javascript
// Settings > FFmpeg
const gpuOptions = [
  { value: "auto", label: "Auto-detect (Prefer NVIDIA > AMD > Intel > CPU)" },
  { value: "nvidia", label: "Force NVIDIA NVENC" },
  { value: "amd", label: "Force AMD AMF" },
  { value: "intel", label: "Force Intel Quick Sync" },
  { value: "cpu", label: "Force CPU (x265)" },
];
```

**BÃ©nÃ©fices** :

- âœ… Support universel de tous les GPU
- âœ… SÃ©lection automatique du meilleur encoder
- âœ… Configuration par utilisateur
- âœ… Fallback intelligent

**Estimation** : 2-3 jours de travail

---

### 11. ImplÃ©menter un SystÃ¨me de MÃ©triques

**Pourquoi** :

- Pas de visibilitÃ© sur les performances rÃ©elles (vitesse SFTP vs WebDAV)
- Impossible d'optimiser le choix auto de protocole
- Pas de statistiques d'usage (combien de Go encodÃ©s, temps moyen, etc.)

**Comment** :

```javascript
// backend/metrics/MetricsCollector.js
class MetricsCollector {
  constructor() {
    this.metrics = {
      transfers: {
        webdav: { downloads: [], uploads: [] },
        sftp: { downloads: [], uploads: [] }
      },
      encodings: {
        gpu: [],
        cpu: []
      },
      jobs: {
        total: 0,
        completed: 0,
        failed: 0,
        retried: 0
      }
    };
  }

  recordTransfer(protocol, operation, size, duration) {
    const speed = size / duration; // bytes per second
    this.metrics.transfers[protocol][operation + 's'].push({
      timestamp: Date.now(),
      size,
      duration,
      speed
    });
  }

  recordEncoding(method, inputSize, outputSize, duration) {
    const compressionRatio = (1 - outputSize / inputSize) * 100;
    this.metrics.encodings[method].push({
      timestamp: Date.now(),
      inputSize,
      outputSize,
      duration,
      compressionRatio,
      speed: inputSize / duration
    });
  }

  getAverageSpeed(protocol, operation) {
    const records = this.metrics.transfers[protocol][operation + 's'];
    if (records.length === 0) return 0;

    const totalSpeed = records.reduce((sum, r) => sum + r.speed, 0);
    return totalSpeed / records.length;
  }

  getBestProtocol(operation, size) {
    const webdavSpeed = this.getAverageSpeed('webdav', operation);
    const sftpSpeed = this.getAverageSpeed('sftp', operation);

    return webdavSpeed > sftpSpeed ? 'webdav' : 'sftp';
  }

  getStats() {
    return {
      totalJobs: this.metrics.jobs.total,
      successRate: this.metrics.jobs.completed / this.metrics.jobs.total,
      avgCompressionRatio: this.getAvgCompressionRatio(),
      totalDataEncoded: this.getTotalDataEncoded(),
      avgEncodingSpeed: this.getAvgEncodingSpeed(),
      protocolPreference: {
        download: this.getBestProtocol('download'),
        upload: this.getBestProtocol('upload')
      }
    };
  }

  save() {
    fs.writeJSON('./metrics.json', this.metrics, { spaces: 2 });
  }

  load() {
    if (fs.existsSync('./metrics.json')) {
      this.metrics = fs.readJSONSync('./metrics.json');
    }
  }
}

// Utilisation dans transfer.js
_chooseDownloadMethod(fileSize) {
  if (this.transferMethod === 'auto') {
    // Use metrics to choose best protocol
    const bestProtocol = metricsCollector.getBestProtocol('download', fileSize);
    return bestProtocol;
  }
  // ... existing logic
}

// UI Dashboard
function MetricsDashboard() {
  const [stats, setStats] = useState(null);

  useEffect(() => {
    const loadStats = async () => {
      const result = await window.electronAPI.getMetrics();
      setStats(result);
    };
    loadStats();
  }, []);

  return (
    <div className="metrics-dashboard">
      <h3>Statistics</h3>
      <div className="stat">Total Jobs: {stats?.totalJobs}</div>
      <div className="stat">Success Rate: {(stats?.successRate * 100).toFixed(1)}%</div>
      <div className="stat">Avg Compression: {stats?.avgCompressionRatio.toFixed(1)}%</div>
      <div className="stat">Total Data Encoded: {formatBytes(stats?.totalDataEncoded)}</div>
    </div>
  );
}
```

**BÃ©nÃ©fices** :

- âœ… Optimisation data-driven du choix de protocole
- âœ… VisibilitÃ© sur les performances
- âœ… Statistiques d'usage intÃ©ressantes
- âœ… Aide au troubleshooting

**Estimation** : 1-2 jours de travail

---

### 12. Ajouter Support SHA256 pour Checksums

**Pourquoi** :

- MD5 considÃ©rÃ© comme faible cryptographiquement
- SHA256 est le standard moderne
- Meilleure dÃ©tection de corruption de fichiers

**Comment** :

```javascript
// backend/utils.js
/**
 * Calculate file hash with configurable algorithm
 * @param {string} filePath - Path to file
 * @param {string} algorithm - Hash algorithm (md5, sha256, sha512)
 * @returns {Promise<string>} Hash digest (hex)
 */
const calculateFileHash = async (filePath, algorithm = 'sha256') => {
  return new Promise((resolve, reject) => {
    const hash = crypto.createHash(algorithm);
    const stream = fs.createReadStream(filePath);

    stream.on('error', reject);
    stream.on('data', (chunk) => hash.update(chunk));
    stream.on('end', () => resolve(hash.digest('hex')));
  });
};

/**
 * Verify file integrity by comparing hashes
 * @param {string} filePath - Path to file
 * @param {string} expectedHash - Expected hash value
 * @param {string} algorithm - Hash algorithm
 * @returns {Promise<boolean>} True if hashes match
 */
const verifyFileIntegrity = async (filePath, expectedHash, algorithm = 'sha256') => {
  const actualHash = await calculateFileHash(filePath, algorithm);
  return actualHash === expectedHash;
};

// Utilisation dans queue.js
async downloadPhase(job) {
  // Download file...

  // Verify integrity if configured
  if (this.config.advanced?.behavior?.verify_checksums) {
    // Get remote hash
    const remoteHash = await this.transferManager.getFileHash(job.filepath);

    // Verify local file
    const isValid = await verifyFileIntegrity(localPath, remoteHash, 'sha256');

    if (!isValid) {
      throw new Error('File integrity check failed - download corrupted');
    }

    logger.info('âœ“ File integrity verified (SHA256)');
  }
}
```

**BÃ©nÃ©fices** :

- âœ… SÃ©curitÃ© amÃ©liorÃ©e
- âœ… DÃ©tection de corruption
- âœ… Standard moderne

**Estimation** : 0.5 jour de travail

---

## ðŸ“Š RÃ‰SUMÃ‰ DES PRIORITÃ‰S

### Matrice Effort / Impact

| TÃ¢che                        | PrioritÃ© | Effort | Impact    | ROI        |
| ---------------------------- | -------- | ------ | --------- | ---------- |
| 1. Refactor Frontend         | ðŸ”´       | 4j     | TrÃ¨s Haut | â­â­â­â­â­ |
| 2. Modulariser queue.js      | ðŸ”´       | 3j     | TrÃ¨s Haut | â­â­â­â­â­ |
| 3. Refactor IPC Handlers     | ðŸ”´       | 2j     | Haut      | â­â­â­â­   |
| 4. Ã‰liminer Code DupliquÃ©    | ðŸ”´       | 0.5j   | Moyen     | â­â­â­â­â­ |
| 5. Migrations DB             | ðŸŸ¡       | 1j     | Moyen     | â­â­â­â­   |
| 6. Disk Space Check          | ðŸŸ¡       | 0.5j   | Moyen     | â­â­â­â­   |
| 7. Tests AutomatisÃ©s         | ðŸŸ¡       | 4j     | TrÃ¨s Haut | â­â­â­â­â­ |
| 8. BaseTransferManager       | ðŸŸ¡       | 2j     | Haut      | â­â­â­â­   |
| 9. Rotation Logs             | ðŸŸ¢       | 0.5j   | Faible    | â­â­â­     |
| 10. Support GPU Multi-vendor | ðŸŸ¢       | 3j     | Moyen     | â­â­â­     |
| 11. SystÃ¨me de MÃ©triques     | ðŸŸ¢       | 2j     | Moyen     | â­â­â­     |
| 12. SHA256 Support           | ðŸŸ¢       | 0.5j   | Faible    | â­â­       |

**Total estimÃ© : 23 jours**

---

## ðŸŽ¯ PLAN D'EXÃ‰CUTION RECOMMANDÃ‰

### Phase 1 : Fondations (Sprint 1 - 2 semaines)

**Objectif** : RÃ©duire dette technique critique

1. âœ… Ã‰liminer code dupliquÃ© (0.5j) - **Quick win**
2. âœ… Disk space check (0.5j) - **Quick win**
3. âœ… Migrations DB (1j)
4. âœ… Modulariser queue.js (3j)
5. âœ… Refactor IPC Handlers (2j)

**Livrables** :

- Code plus maintenable
- Modules testables
- Risques rÃ©duits

### Phase 2 : Modernisation Frontend (Sprint 2 - 1 semaine)

**Objectif** : UI moderne et performante

6. âœ… Refactor Frontend complet (4j)
   - Setup build process
   - DÃ©coupage composants
   - Custom hooks
   - Tests composants

**Livrables** :

- App React moderne
- Hot reload
- Bundle optimisÃ©

### Phase 3 : QualitÃ© & Tests (Sprint 3 - 1 semaine)

**Objectif** : Confiance et stabilitÃ©

7. âœ… Tests automatisÃ©s (4j)
   - Tests unitaires backend
   - Tests composants React
   - Tests intÃ©gration
   - CI/CD setup

**Livrables** :

- Couverture >80%
- Tests automatisÃ©s
- CI/CD pipeline

### Phase 4 : Optimisations (Sprint 4 - 1 semaine)

**Objectif** : Performance et features

8. âœ… BaseTransferManager (2j)
9. âœ… Rotation logs (0.5j)
10. âœ… SHA256 support (0.5j)

**Livrables** :

- Code factorisÃ©
- Logs gÃ©rÃ©s
- Checksums modernes

### Phase 5 : Extensions (Sprint 5 - optionnel)

**Objectif** : Nouvelles fonctionnalitÃ©s

11. âœ… Support GPU multi-vendor (3j)
12. âœ… SystÃ¨me de mÃ©triques (2j)

**Livrables** :

- Support AMD/Intel GPU
- Dashboard statistiques

---

## ðŸ”§ DESIGN PATTERNS UTILISÃ‰S

### Patterns Actuels (Ã€ PrÃ©server)

- âœ… **Event-Driven Architecture** : EventEmitter pour queue, encoder
- âœ… **Strategy Pattern** : TransferManager (auto/sftp/webdav)
- âœ… **Facade Pattern** : QueueManager orchestrant le pipeline
- âœ… **Observer Pattern** : IPC events pour UI updates

### Patterns Ã€ Introduire

- ðŸ†• **State Pattern** : JobStateMachine pour gestion d'Ã©tats
- ðŸ†• **Template Method** : BaseTransferManager
- ðŸ†• **Router Pattern** : IPC routing par domaine
- ðŸ†• **Middleware Pattern** : Chain of responsibility pour IPC
- ðŸ†• **Component Composition** : React composants
- ðŸ†• **Custom Hooks** : Logique IPC rÃ©utilisable
- ðŸ†• **Factory Pattern** : CrÃ©ation d'objets de test

### Principes SOLID Ã€ Appliquer

- **S**ingle Responsibility : Un fichier = une responsabilitÃ©
- **O**pen/Closed : Extension via plugins, pas modification
- **L**iskov Substitution : BaseTransferManager substituable
- **I**nterface Segregation : Interfaces spÃ©cifiques
- **D**ependency Inversion : Injection de dÃ©pendances

---

## ðŸ“š DOCUMENTATION Ã€ CRÃ‰ER

1. **Architecture Decision Records (ADR)**

   - Pourquoi ces choix techniques
   - Historique des dÃ©cisions

2. **Diagrammes**

   - Architecture globale
   - SÃ©quence du pipeline
   - Diagramme de classes
   - Flow IPC

3. **Guide de Contribution**

   - Setup dev environment
   - Conventions de code
   - Process de PR

4. **Guide de Tests**
   - Comment Ã©crire des tests
   - Fixtures et mocks
   - Coverage requirements

---

## âœ… CRITÃˆRES DE SUCCÃˆS

### MÃ©triques Objectives

- [ ] Fichiers < 300 lignes (80%+ du code)
- [ ] Couverture de tests > 80%
- [ ] Build time < 30 secondes
- [ ] Bundle size < 5MB
- [ ] Pas de code dupliquÃ© (DRY violations = 0)
- [ ] ComplexitÃ© cyclomatique < 10 par fonction

### MÃ©triques Qualitatives

- [ ] Code review en < 30 min
- [ ] Onboarding nouveau dev < 1 jour
- [ ] Ajout nouvelle feature < 1 jour
- [ ] Bug fix < 2 heures

---

## ðŸš€ PROCHAINES Ã‰TAPES

**Aujourd'hui** :

1. Lire et valider ce TODO avec l'Ã©quipe
2. Prioriser les tÃ¢ches selon le contexte projet
3. CrÃ©er les issues GitHub correspondantes

**Cette semaine** :

1. Commencer Phase 1 (fondations)
2. Setup environnement de tests
3. Documenter dÃ©cisions d'architecture

**Ce mois** :

1. ComplÃ©ter Phases 1-3
2. Release v2.0 avec code refactorÃ©
3. DÃ©marrer Phase 4

---

**Note** : Ce TODO est un guide, pas un dogme. Adapter selon :

- Les prioritÃ©s business
- Les ressources disponibles
- Les feedbacks utilisateurs
- Les contraintes techniques Ã©mergentes

**Principe** : Better done than perfect. ItÃ©rer et amÃ©liorer progressivement.
